{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN model for tree classification based on images of their bark\n",
    "In this notebook a CNN model will be developed to classify bark according to tree species. The CNN will be trained to classify the original images. After the training the CNN will be evaluated with some post-hoc model analysis methods like LIME and SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing the data structure (only done once, after downloading the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the dataset (https://www.kaggle.com/datasets/saurabhshahane/barkvn50) should be downloaded to directory: \"./data/BarkVN-50/\" and unzipped. You should then have the following structure:\n",
    "- data\n",
    "    - BarkVN-50\n",
    "        - BarkVN-50_mendeley\n",
    "            - Acacia\n",
    "            - Adenanthera microsperma\n",
    "            - Adenieum species\n",
    "            - Anacardium occidentale\n",
    "            - ...\n",
    "\n",
    "Since this is not ideal for this CNN, a subset of the data is selected and split into training data using the code in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helpers.split\n",
    "# helpers.split.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this cell only needs to be executed once (this is why it is commented out by default).\n",
    "\n",
    "After execution the new data structure looks like this:\n",
    "- data\n",
    "    - BarkVN-50\n",
    "        - BarkVN-50_mendeley\n",
    "            - Acacia\n",
    "            - Adenanthera microsperma\n",
    "            - Adenieum species\n",
    "            - Anacardium occidentale\n",
    "            - ...\n",
    "        - Test\n",
    "            - Adenanthera microsperma\n",
    "            - Cananga odorata\n",
    "            - Cedrus\n",
    "            - Cocos nucifera\n",
    "            - Dalvergia oliveri\n",
    "        - Train\n",
    "            - Adenanthera microsperma\n",
    "            - Cananga odorata\n",
    "            - Cedrus\n",
    "            - Cocos nucifera\n",
    "            - Dalvergia oliveri\n",
    "\n",
    "Note: the directory \"./data/BarkVN-50/BarkVN-50_mendeley\" may be deleted after this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset and creating DataLoaders\n",
    "Since the used dataset is a custom one, we need to first create a custom Dataset for loading, transforming and delivering datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.dataset import BarkVN50Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import device\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# recognizing device\n",
    "DEVICE = device(\"cuda\" if is_available() else \"cpu\")\n",
    "\n",
    "# load train dataset and create DataLoaders that automatically create minibatches and shuffle the data\n",
    "train_dataset = BarkVN50Dataset(train=True, device=DEVICE)\n",
    "test_dataset = BarkVN50Dataset(train=False, device=DEVICE)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=39, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "Now that the data is ready to be used, we can load the CNN model (or resume training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.cnn import ConvolutionalNeuralNetwork\n",
    "\n",
    "model = ConvolutionalNeuralNetwork()\n",
    "model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the hyperaparameters, optimizer and the criterion (loss function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# optimizer and loss function\n",
    "model.train()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an already existing model should be trained, it can be loaded from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import load\n",
    "\n",
    "# checkpoint = load(\"models/checkpoint-2024-11-04-18-14-59.tar\", weights_only=True)\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# epoch = checkpoint[\"epoch\"]\n",
    "# loss = checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN model\n",
    "And finally train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.train import train_cnn\n",
    "\n",
    "train_cnn(\n",
    "    num_epochs=num_epochs,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trained model can be evaluated before we save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.evaluate import evaluate_cnn\n",
    "\n",
    "evaluate_cnn(\n",
    "    criterion=criterion,\n",
    "    test_dataloader=test_dataloader,\n",
    "    train_dataloader=train_dataloader,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model should be trained again later on, it can be saved using the .tar (PyTorch convention for model checkpoints) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "from datetime import datetime\n",
    "\n",
    "time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "save(\n",
    "    {\n",
    "        \"epoch\": num_epochs,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": 123,\n",
    "    },\n",
    "    f\"models/checkpoint-{num_epochs}ep-{time}.tar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it shouldn't be trainable, but nonetheless be evaluated, only the model's state_dictionary can be saved with the .pt format (PyTorch convention for finished models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "from datetime import datetime\n",
    "\n",
    "time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "save(model.state_dict(), f\"models/eval-model-{num_epochs}ep-{time}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
